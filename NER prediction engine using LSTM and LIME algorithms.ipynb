{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm, trange","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/ner-dataset/ner_datasetreference.csv', encoding='latin1')\ndata = data.fillna(method='ffill')\ndata.head(20)","metadata":{"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"     Sentence #           Word  POS    Tag\n0   Sentence: 1      Thousands  NNS      O\n1   Sentence: 1             of   IN      O\n2   Sentence: 1  demonstrators  NNS      O\n3   Sentence: 1           have  VBP      O\n4   Sentence: 1        marched  VBN      O\n5   Sentence: 1        through   IN      O\n6   Sentence: 1         London  NNP  B-geo\n7   Sentence: 1             to   TO      O\n8   Sentence: 1        protest   VB      O\n9   Sentence: 1            the   DT      O\n10  Sentence: 1            war   NN      O\n11  Sentence: 1             in   IN      O\n12  Sentence: 1           Iraq  NNP  B-geo\n13  Sentence: 1            and   CC      O\n14  Sentence: 1         demand   VB      O\n15  Sentence: 1            the   DT      O\n16  Sentence: 1     withdrawal   NN      O\n17  Sentence: 1             of   IN      O\n18  Sentence: 1        British   JJ  B-gpe\n19  Sentence: 1         troops  NNS      O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sentence: 1</td>\n      <td>Thousands</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sentence: 1</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sentence: 1</td>\n      <td>demonstrators</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sentence: 1</td>\n      <td>have</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sentence: 1</td>\n      <td>marched</td>\n      <td>VBN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Sentence: 1</td>\n      <td>through</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Sentence: 1</td>\n      <td>London</td>\n      <td>NNP</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Sentence: 1</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Sentence: 1</td>\n      <td>protest</td>\n      <td>VB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Sentence: 1</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Sentence: 1</td>\n      <td>war</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Sentence: 1</td>\n      <td>in</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Sentence: 1</td>\n      <td>Iraq</td>\n      <td>NNP</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Sentence: 1</td>\n      <td>and</td>\n      <td>CC</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Sentence: 1</td>\n      <td>demand</td>\n      <td>VB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Sentence: 1</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Sentence: 1</td>\n      <td>withdrawal</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Sentence: 1</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Sentence: 1</td>\n      <td>British</td>\n      <td>JJ</td>\n      <td>B-gpe</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Sentence: 1</td>\n      <td>troops</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.tail(10)","metadata":{"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"              Sentence #       Word  POS    Tag\n1048565  Sentence: 47958     impact   NN      O\n1048566  Sentence: 47958          .    .      O\n1048567  Sentence: 47959     Indian   JJ  B-gpe\n1048568  Sentence: 47959     forces  NNS      O\n1048569  Sentence: 47959       said  VBD      O\n1048570  Sentence: 47959       they  PRP      O\n1048571  Sentence: 47959  responded  VBD      O\n1048572  Sentence: 47959         to   TO      O\n1048573  Sentence: 47959        the   DT      O\n1048574  Sentence: 47959     attack   NN      O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1048565</th>\n      <td>Sentence: 47958</td>\n      <td>impact</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048566</th>\n      <td>Sentence: 47958</td>\n      <td>.</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048567</th>\n      <td>Sentence: 47959</td>\n      <td>Indian</td>\n      <td>JJ</td>\n      <td>B-gpe</td>\n    </tr>\n    <tr>\n      <th>1048568</th>\n      <td>Sentence: 47959</td>\n      <td>forces</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048569</th>\n      <td>Sentence: 47959</td>\n      <td>said</td>\n      <td>VBD</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048570</th>\n      <td>Sentence: 47959</td>\n      <td>they</td>\n      <td>PRP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048571</th>\n      <td>Sentence: 47959</td>\n      <td>responded</td>\n      <td>VBD</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048572</th>\n      <td>Sentence: 47959</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048573</th>\n      <td>Sentence: 47959</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1048574</th>\n      <td>Sentence: 47959</td>\n      <td>attack</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"words = list(set(data[\"Word\"].values))\nn_words = len(words); n_words","metadata":{"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"35178"},"metadata":{}}]},{"cell_type":"code","source":"tags = list(set(data[\"Tag\"].values))\nn_tags = len(tags); n_tags\n","metadata":{"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"17"},"metadata":{}}]},{"cell_type":"code","source":"class SentenceGetter(object):\n    def __init__(self, data):\n        self.data = data\n        agg_fun = lambda s: [(w, p, t) for w,p,t in zip(s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].values.tolist())]\n        self.grouped = self.data.groupby('Sentence #').apply(agg_fun)\n        self.sentences = [i for i in self.grouped]\n    def get_next(self):\n        try:\n            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n            self.n_sent += 1\n            return s\n        except:\n            return None","metadata":{"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"getter = SentenceGetter(data)\nsentences = getter.sentences","metadata":{"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"labels = [[s[2] for s in sent] for sent in sentences]\nsentences = [\" \".join([s[0] for s in sent]) for sent in sentences]\nsentences[0]","metadata":{"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .'"},"metadata":{}}]},{"cell_type":"code","source":"print(labels[0])","metadata":{"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n","output_type":"stream"}]},{"cell_type":"code","source":"from collections import Counter\nimport keras\nfrom keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"word_cnt = Counter(data[\"Word\"].values)\nvocabulary = set(w[0] for w in word_cnt.most_common(5000))","metadata":{"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"max_len = 50\nword2idx = {\"PAD\" : 0, \"UNK\": 1}\nword2idx.update({w: i for i,w in enumerate(words) if w in vocabulary})\ntag2idx = {t: i for i,t in enumerate(tags)}","metadata":{"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"X = [[word2idx.get(w, word2idx[\"UNK\"]) for w in s.split()] for s in sentences]","metadata":{"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=word2idx[\"PAD\"])","metadata":{"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"y = [[tag2idx[l_i] for l_i in l] for l in labels]","metadata":{"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])","metadata":{"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_tr, X_te, y_tr, y_te = train_test_split(X,y,test_size=0.1, shuffle=False)","metadata":{"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model, Input\nfrom keras.layers import LSTM, Embedding, Dense, TimeDistributed, SpatialDropout1D, Bidirectional","metadata":{"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"word_input = Input(shape=(max_len,))\nmodel = Embedding(input_dim=n_words, output_dim = 50, input_length=max_len)(word_input)\nmodel = SpatialDropout1D(0.1)(model)\nmodel = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\nout = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)","metadata":{"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"model = Model(word_input, out)\nmodel.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n","metadata":{"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_tr, y_tr.reshape(*y_tr.shape, 1), batch_size = 32, epochs=5, validation_split=0.1, verbose=1)","metadata":{"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Epoch 1/5\n1214/1214 [==============================] - 126s 100ms/step - loss: 0.2557 - accuracy: 0.9441 - val_loss: 0.0704 - val_accuracy: 0.9797\nEpoch 2/5\n1214/1214 [==============================] - 124s 102ms/step - loss: 0.0663 - accuracy: 0.9805 - val_loss: 0.0604 - val_accuracy: 0.9823\nEpoch 3/5\n1214/1214 [==============================] - 123s 101ms/step - loss: 0.0591 - accuracy: 0.9824 - val_loss: 0.0580 - val_accuracy: 0.9830\nEpoch 4/5\n1214/1214 [==============================] - 124s 102ms/step - loss: 0.0544 - accuracy: 0.9837 - val_loss: 0.0561 - val_accuracy: 0.9833\nEpoch 5/5\n1214/1214 [==============================] - 124s 102ms/step - loss: 0.0526 - accuracy: 0.9842 - val_loss: 0.0551 - val_accuracy: 0.9835\n","output_type":"stream"}]},{"cell_type":"code","source":"from eli5.lime import TextExplainer\nfrom eli5.lime.samplers import MaskingTextSampler","metadata":{"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"code","source":"class NERExplainerGenerator(object):\n    \n    def __init__(self, model, word2idx, tag2idx, max_len):\n        self.model = model\n        self.word2idx = word2idx\n        self.tag2idx = tag2idx\n        self.idx2tag = {v: k for k,v in tag2idx.items()}\n        self.max_len = max_len\n        \n    def _preprocess(self, texts):\n        X = [[self.word2idx.get(w, self.word2idx[\"UNK\"]) for w in t.split()]\n             for t in texts]\n        X = pad_sequences(maxlen=self.max_len, sequences=X,\n                          padding=\"post\", value=self.word2idx[\"PAD\"])\n        return X\n    \n    def get_predict_function(self, word_index):\n        def predict_func(texts):\n            X = self._preprocess(texts)\n            p = self.model.predict(X)\n            return p[:,word_index,:]\n        return predict_func\n","metadata":{"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"index = 46781\nlabel =labels[index]\ntext = sentences[index]\nprint(text)\nprint()\nprint(\" \".join([f\"{t} ({l})\" for t, l in zip(text.split(), label)]))","metadata":{"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\n\nNigeria (B-geo) 's (O) President (B-per) Olusegun (I-per) Obasanjo (I-per) expressed (O) his (O) condolences (O) , (O) noting (O) the (O) late (O) pontiff (O) promoted (O) religious (O) tolerance (O) and (O) democracy (O) in (O) the (O) West (O) African (B-gpe) nation (O) . (O)\n","output_type":"stream"}]},{"cell_type":"code","source":"for i, w in enumerate(text.split()):\n    print(f\"{i}: {w}\")","metadata":{"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"0: Nigeria\n1: 's\n2: President\n3: Olusegun\n4: Obasanjo\n5: expressed\n6: his\n7: condolences\n8: ,\n9: noting\n10: the\n11: late\n12: pontiff\n13: promoted\n14: religious\n15: tolerance\n16: and\n17: democracy\n18: in\n19: the\n20: West\n21: African\n22: nation\n23: .\n","output_type":"stream"}]},{"cell_type":"code","source":"explainer_generator = NERExplainerGenerator(model, word2idx, tag2idx, max_len)\n","metadata":{"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"word_index = 4\npredict_func = explainer_generator.get_predict_function(word_index=word_index)\n","metadata":{"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"sampler = MaskingTextSampler(\n    replacement=\"UNK\",\n    max_replace=0.7,\n    token_pattern=None,\n    bow=False\n)\n","metadata":{"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"samples, similarity = sampler.sample_near(text, n_samples=4)\nprint(samples)\n","metadata":{"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"(\"Nigeria 's President UNK UNK expressed UNK condolences , noting the UNK pontiff UNK religious UNK and UNK UNK the UNK UNK nation .\", \"UNK 'UNK UNK Olusegun UNK expressed his condolences , UNK the UNK UNK UNK UNK tolerance UNK democracy UNK UNK UNK African nation .\", \"Nigeria 'UNK UNK Olusegun Obasanjo UNK his condolences , UNK UNK UNK pontiff promoted UNK UNK UNK UNK UNK UNK UNK UNK UNK .\", \"Nigeria 's President UNK Obasanjo expressed his condolences , UNK UNK late pontiff promoted religious tolerance UNK democracy in the West African UNK .\")\n","output_type":"stream"}]},{"cell_type":"code","source":"te = TextExplainer(\n    sampler=sampler,\n    position_dependent=True,\n    random_state=42\n)\n\nte.fit(text, predict_func)\n\nte.explain_prediction(\n    target_names=list(explainer_generator.idx2tag.values()),\n    top_targets=3\n)\n","metadata":{"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"Explanation(estimator=\"SGDClassifier(alpha=0.001, loss='log', penalty='elasticnet',\\n              random_state=RandomState(MT19937) at 0x7FBF59C67C00)\", description=None, error=None, method='linear model', is_regression=False, targets=[TargetExplanation(target='I-per', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='[2] President', weight=2.5739990295113286, std=None, value=1.0), FeatureWeight(feature='[4] Obasanjo', weight=1.406204366928379, std=None, value=1.0), FeatureWeight(feature='[5] expressed', weight=0.7819273122550882, std=None, value=1.0), FeatureWeight(feature='[18] the', weight=0.07682645617363369, std=None, value=1.0), FeatureWeight(feature='[6] his', weight=0.06977423094653004, std=None, value=1.0), FeatureWeight(feature='[17] in', weight=0.06731509203466216, std=None, value=1.0), FeatureWeight(feature='[9] the', weight=0.04845441735154441, std=None, value=1.0), FeatureWeight(feature='[3] Olusegun', weight=0.037829120737674006, std=None, value=1.0), FeatureWeight(feature='[19] West', weight=0.03409077869928415, std=None, value=1.0), FeatureWeight(feature='[16] democracy', weight=0.007001506560378559, std=None, value=1.0)], neg=[FeatureWeight(feature='[1] s', weight=-0.9011070419835913, std=None, value=1.0), FeatureWeight(feature='[0] Nigeria', weight=-0.22321377434669895, std=None, value=1.0), FeatureWeight(feature='[7] condolences', weight=-0.11008865412213072, std=None, value=1.0), FeatureWeight(feature='<BIAS>', weight=-0.08140924868651354, std=None, value=1.0), FeatureWeight(feature='[21] nation', weight=-0.041720864533927295, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.969492220992907, score=3.7458827275256414, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document=\"Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\", spans=[('Nigeria', [(0, 7)], -0.22321377434669895), ('s', [(9, 10)], -0.9011070419835913), ('President', [(11, 20)], 2.5739990295113286), ('Olusegun', [(21, 29)], 0.037829120737674006), ('Obasanjo', [(30, 38)], 1.406204366928379), ('expressed', [(39, 48)], 0.7819273122550882), ('his', [(49, 52)], 0.06977423094653004), ('condolences', [(53, 64)], -0.11008865412213072), ('the', [(74, 77)], 0.04845441735154441), ('democracy', [(124, 133)], 0.007001506560378559), ('in', [(134, 136)], 0.06731509203466216), ('the', [(137, 140)], 0.07682645617363369), ('West', [(141, 145)], 0.03409077869928415), ('nation', [(154, 160)], -0.041720864533927295)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=3.827291976212154, std=None, value=None)], neg=[FeatureWeight(feature='<BIAS>', weight=-0.08140924868651354, std=None, value=1.0)], pos_remaining=0, neg_remaining=0)), heatmap=None), TargetExplanation(target='B-per', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='[1] s', weight=0.14004717180117188, std=None, value=1.0), FeatureWeight(feature='[7] condolences', weight=0.04367333233683503, std=None, value=1.0), FeatureWeight(feature='[9] the', weight=0.03997526363170428, std=None, value=1.0), FeatureWeight(feature='[16] democracy', weight=0.019825770580646898, std=None, value=1.0), FeatureWeight(feature='[11] pontiff', weight=0.01061596582660963, std=None, value=1.0), FeatureWeight(feature='[15] and', weight=0.01043111207085134, std=None, value=1.0), FeatureWeight(feature='[6] his', weight=0.0009070746780105845, std=None, value=1.0)], neg=[FeatureWeight(feature='<BIAS>', weight=-2.3590579591544736, std=None, value=1.0), FeatureWeight(feature='[2] President', weight=-1.4037406382811264, std=None, value=1.0), FeatureWeight(feature='[5] expressed', weight=-0.7389441635353861, std=None, value=1.0), FeatureWeight(feature='[14] tolerance', weight=-0.0980474037461294, std=None, value=1.0), FeatureWeight(feature='[17] in', weight=-0.055101751238779, std=None, value=1.0), FeatureWeight(feature='[13] religious', weight=-0.03443868919556113, std=None, value=1.0), FeatureWeight(feature='[21] nation', weight=-0.0333682694341913, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.011374360154353004, score=-4.457223183659817, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document=\"Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\", spans=[('s', [(9, 10)], 0.14004717180117188), ('President', [(11, 20)], -1.4037406382811264), ('expressed', [(39, 48)], -0.7389441635353861), ('his', [(49, 52)], 0.0009070746780105845), ('condolences', [(53, 64)], 0.04367333233683503), ('the', [(74, 77)], 0.03997526363170428), ('pontiff', [(83, 90)], 0.01061596582660963), ('religious', [(100, 109)], -0.03443868919556113), ('tolerance', [(110, 119)], -0.0980474037461294), ('and', [(120, 123)], 0.01043111207085134), ('democracy', [(124, 133)], 0.019825770580646898), ('in', [(134, 136)], -0.055101751238779), ('nation', [(154, 160)], -0.0333682694341913)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[], neg=[FeatureWeight(feature='<BIAS>', weight=-2.3590579591544736, std=None, value=1.0), FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=-2.0981652245053435, std=None, value=None)], pos_remaining=0, neg_remaining=0)), heatmap=None), TargetExplanation(target='I-org', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='[1] s', weight=0.59079482026114, std=None, value=1.0), FeatureWeight(feature='[0] Nigeria', weight=0.1084464585850336, std=None, value=1.0), FeatureWeight(feature='[7] condolences', weight=0.03795287823272028, std=None, value=1.0), FeatureWeight(feature='[13] religious', weight=0.032802877545960084, std=None, value=1.0), FeatureWeight(feature='[21] nation', weight=0.02729372372571879, std=None, value=1.0)], neg=[FeatureWeight(feature='[2] President', weight=-2.8439259081206227, std=None, value=1.0), FeatureWeight(feature='<BIAS>', weight=-1.307274141903415, std=None, value=1.0), FeatureWeight(feature='[4] Obasanjo', weight=-1.0845691224741654, std=None, value=1.0), FeatureWeight(feature='[5] expressed', weight=-0.25485993962416975, std=None, value=1.0), FeatureWeight(feature='[6] his', weight=-0.2096767398456018, std=None, value=1.0), FeatureWeight(feature='[16] democracy', weight=-0.14849420321094592, std=None, value=1.0), FeatureWeight(feature='[18] the', weight=-0.10296339137288106, std=None, value=1.0), FeatureWeight(feature='[17] in', weight=-0.08342552946392272, std=None, value=1.0), FeatureWeight(feature='[12] promoted', weight=-0.06458612951283395, std=None, value=1.0), FeatureWeight(feature='[19] West', weight=-0.05143978337236898, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.004671453071159821, score=-5.353924130550355, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document=\"Nigeria 's President Olusegun Obasanjo expressed his condolences , noting the late pontiff promoted religious tolerance and democracy in the West African nation .\", spans=[('Nigeria', [(0, 7)], 0.1084464585850336), ('s', [(9, 10)], 0.59079482026114), ('President', [(11, 20)], -2.8439259081206227), ('Obasanjo', [(30, 38)], -1.0845691224741654), ('expressed', [(39, 48)], -0.25485993962416975), ('his', [(49, 52)], -0.2096767398456018), ('condolences', [(53, 64)], 0.03795287823272028), ('promoted', [(91, 99)], -0.06458612951283395), ('religious', [(100, 109)], 0.032802877545960084), ('democracy', [(124, 133)], -0.14849420321094592), ('in', [(134, 136)], -0.08342552946392272), ('the', [(137, 140)], -0.10296339137288106), ('West', [(141, 145)], -0.05143978337236898), ('nation', [(154, 160)], 0.02729372372571879)], preserve_density=False, vec_name=None)], other=FeatureWeights(pos=[], neg=[FeatureWeight(feature=<FormattedFeatureName 'Highlighted in text (sum)'>, weight=-4.046649988646939, std=None, value=None), FeatureWeight(feature='<BIAS>', weight=-1.307274141903415, std=None, value=1.0)], pos_remaining=0, neg_remaining=0)), heatmap=None)], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None, image=None)","text/html":"\n    <style>\n    table.eli5-weights tr:hover {\n        filter: brightness(85%);\n    }\n</style>\n\n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n        \n\n    \n\n    \n        \n    \n        \n        \n    \n        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n            <b>\n    \n        y=I-per\n    \n</b>\n\n    \n    (probability <b>0.969</b>, score <b>3.746</b>)\n\ntop features\n        </p>\n    \n    <table class=\"eli5-weights\"\n           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n        <thead>\n        <tr style=\"border: none;\">\n            \n                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n                    Contribution<sup>?</sup>\n                </th>\n            \n            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n            \n        </tr>\n        </thead>\n        <tbody>\n        \n            <tr style=\"background-color: hsl(120, 100.00%, 80.77%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        +3.827\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        Highlighted in text (sum)\n    </td>\n    \n</tr>\n        \n        \n\n        \n        \n            <tr style=\"background-color: hsl(0, 100.00%, 98.70%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -0.081\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        &lt;BIAS&gt;\n    </td>\n    \n</tr>\n        \n\n        </tbody>\n    </table>\n\n    \n\n\n\n    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n        <span style=\"background-color: hsl(0, 100.00%, 93.26%); opacity: 0.82\" title=\"-0.223\">Nigeria</span><span style=\"opacity: 0.80\"> &#x27;</span><span style=\"background-color: hsl(0, 100.00%, 82.11%); opacity: 0.86\" title=\"-0.901\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 62.70%); opacity: 0.98\" title=\"2.574\">President</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.06%); opacity: 0.80\" title=\"0.038\">Olusegun</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.57%); opacity: 0.90\" title=\"1.406\">Obasanjo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.80%); opacity: 0.85\" title=\"0.782\">expressed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.02%); opacity: 0.80\" title=\"0.070\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.89%); opacity: 0.81\" title=\"-0.110\">condolences</span><span style=\"opacity: 0.80\"> , noting </span><span style=\"background-color: hsl(120, 100.00%, 98.58%); opacity: 0.80\" title=\"0.024\">the</span><span style=\"opacity: 0.80\"> late pontiff promoted religious tolerance and </span><span style=\"background-color: hsl(120, 100.00%, 99.40%); opacity: 0.80\" title=\"0.007\">democracy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.09%); opacity: 0.80\" title=\"0.067\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.03%); opacity: 0.80\" title=\"0.038\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.19%); opacity: 0.80\" title=\"0.034\">West</span><span style=\"opacity: 0.80\"> African </span><span style=\"background-color: hsl(0, 100.00%, 97.92%); opacity: 0.80\" title=\"-0.042\">nation</span><span style=\"opacity: 0.80\"> .</span>\n    </p>\n\n    \n        \n    \n        \n        \n    \n        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n            <b>\n    \n        y=B-per\n    \n</b>\n\n    \n    (probability <b>0.011</b>, score <b>-4.457</b>)\n\ntop features\n        </p>\n    \n    <table class=\"eli5-weights\"\n           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n        <thead>\n        <tr style=\"border: none;\">\n            \n                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n                    Contribution<sup>?</sup>\n                </th>\n            \n            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n            \n        </tr>\n        </thead>\n        <tbody>\n        \n        \n\n        \n        \n            <tr style=\"background-color: hsl(0, 100.00%, 87.37%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -2.098\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        Highlighted in text (sum)\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 86.29%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -2.359\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        &lt;BIAS&gt;\n    </td>\n    \n</tr>\n        \n\n        </tbody>\n    </table>\n\n    \n\n\n\n    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n        <span style=\"opacity: 0.80\">Nigeria &#x27;</span><span style=\"background-color: hsl(120, 100.00%, 95.14%); opacity: 0.81\" title=\"0.140\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.60%); opacity: 0.90\" title=\"-1.404\">President</span><span style=\"opacity: 0.80\"> Olusegun Obasanjo </span><span style=\"background-color: hsl(0, 100.00%, 84.43%); opacity: 0.85\" title=\"-0.739\">expressed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.86%); opacity: 0.80\" title=\"0.001\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.85%); opacity: 0.80\" title=\"0.044\">condolences</span><span style=\"opacity: 0.80\"> , noting </span><span style=\"background-color: hsl(120, 100.00%, 97.98%); opacity: 0.80\" title=\"0.040\">the</span><span style=\"opacity: 0.80\"> late </span><span style=\"background-color: hsl(120, 100.00%, 99.20%); opacity: 0.80\" title=\"0.011\">pontiff</span><span style=\"opacity: 0.80\"> promoted </span><span style=\"background-color: hsl(0, 100.00%, 98.18%); opacity: 0.80\" title=\"-0.034\">religious</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.21%); opacity: 0.81\" title=\"-0.098\">tolerance</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.21%); opacity: 0.80\" title=\"0.010\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.76%); opacity: 0.80\" title=\"0.020\">democracy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.47%); opacity: 0.80\" title=\"-0.055\">in</span><span style=\"opacity: 0.80\"> the West African </span><span style=\"background-color: hsl(0, 100.00%, 98.22%); opacity: 0.80\" title=\"-0.033\">nation</span><span style=\"opacity: 0.80\"> .</span>\n    </p>\n\n    \n        \n    \n        \n        \n    \n        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n            <b>\n    \n        y=I-org\n    \n</b>\n\n    \n    (probability <b>0.005</b>, score <b>-5.354</b>)\n\ntop features\n        </p>\n    \n    <table class=\"eli5-weights\"\n           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n        <thead>\n        <tr style=\"border: none;\">\n            \n                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n                    Contribution<sup>?</sup>\n                </th>\n            \n            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n            \n        </tr>\n        </thead>\n        <tbody>\n        \n        \n\n        \n        \n            <tr style=\"background-color: hsl(0, 100.00%, 90.93%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -1.307\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        &lt;BIAS&gt;\n    </td>\n    \n</tr>\n        \n            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n        -4.047\n    </td>\n    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n        Highlighted in text (sum)\n    </td>\n    \n</tr>\n        \n\n        </tbody>\n    </table>\n\n    \n\n\n\n    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n        <span style=\"background-color: hsl(120, 100.00%, 95.94%); opacity: 0.81\" title=\"0.108\">Nigeria</span><span style=\"opacity: 0.80\"> &#x27;</span><span style=\"background-color: hsl(120, 100.00%, 86.69%); opacity: 0.84\" title=\"0.591\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-2.844\">President</span><span style=\"opacity: 0.80\"> Olusegun </span><span style=\"background-color: hsl(0, 100.00%, 79.63%); opacity: 0.88\" title=\"-1.085\">Obasanjo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.61%); opacity: 0.82\" title=\"-0.255\">expressed</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.55%); opacity: 0.81\" title=\"-0.210\">his</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.05%); opacity: 0.80\" title=\"0.038\">condolences</span><span style=\"opacity: 0.80\"> , noting the late pontiff </span><span style=\"background-color: hsl(0, 100.00%, 97.17%); opacity: 0.80\" title=\"-0.065\">promoted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.24%); opacity: 0.80\" title=\"0.033\">religious</span><span style=\"opacity: 0.80\"> tolerance and </span><span style=\"background-color: hsl(0, 100.00%, 94.94%); opacity: 0.81\" title=\"-0.148\">democracy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.62%); opacity: 0.81\" title=\"-0.083\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.08%); opacity: 0.81\" title=\"-0.103\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.59%); opacity: 0.80\" title=\"-0.051\">West</span><span style=\"opacity: 0.80\"> African </span><span style=\"background-color: hsl(120, 100.00%, 98.45%); opacity: 0.80\" title=\"0.027\">nation</span><span style=\"opacity: 0.80\"> .</span>\n    </p>\n\n    \n\n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n\n"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}